{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e601d278-d0f2-42d6-9f91-92905af2933e",
   "metadata": {},
   "source": [
    "## 课程说明："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321049d5-8716-48c8-be22-0aa037fad731",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同学们好！欢迎来到《机器学习实战训练营》试学体验课！我是课程主讲老师，九天。        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3232869-42e0-4616-9d78-ec5bb2f71fed",
   "metadata": {},
   "source": [
    "- 本期公开课主题：LightGBM原理与实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a1242c-1723-444a-b5ee-8578777ad7e4",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202304301856951.png\" alt=\"8ef6d1e3b063109eb052bb7021c01bd\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ebc33-9f59-4bd5-ab66-f2e39f1cf223",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LightGBM 是一种高效的 Gradient Boosting 算法，由 Microsoft Research Asia 团队开发，早期为Microsoft内部处理海量高维数据的专用算法，并于2017年由Guolin Ke, Qi Meng, Thomas Finley等人通过论文形式正式发布。如果说XGB为GBDT类算法在提升计算精度上做出了里程碑式的突破，那么LGBM则是在计算效率和内存优化上提出了开创性的解决方案，一举将GBDT类算法计算效率提高了近20倍、并且计算内存占用减少了80%，这也最终使得GBDT类算法、这一机器学习领域目前最高精度的预测类算法，能够真正应用于海量数据的建模预测。以下是官网给出的XGB、基于直方图优化的XGB和LGBM算法的在相同计算任务下计算时间的对比："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961c159-746c-4a4a-b2b2-8373c4b400d0",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202304081540395.png\" alt=\"0a747b1752ff4c7c9b368d7415b398c\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d989d96-c376-4129-8db0-0b000712d200",
   "metadata": {},
   "source": [
    "而在内存占用方面，LGBM算法的优势也同样非常明显，以下是相同计算任务下不同算法的内存占用对比："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60859d9-15dd-464c-b997-97be89dbc2d2",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202304081540578.png\" alt=\"a884b5b53ebd9665f526b82d74ca56b\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4c39a-e400-455f-a2ac-2356748e9d3a",
   "metadata": {},
   "source": [
    "而与此同时，LGBM能够保持和XGB几乎一样的预测精度，相同计算任务三种算法计算准确率如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18f8c7c-a56a-4c77-a01e-1cc52faf0124",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202304081550947.png\" alt=\"1680940216389\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74548a4-57be-45dd-88fb-7462e2800706",
   "metadata": {},
   "source": [
    "不难发现，预测精准而计算过程高效，这也是Light一词的核心精髓，并且经过这么多年的实践验证，可以说目前来看，LightGBM已然成为处理海量数据最高效、最通用的机器学习算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3492c7f5-5a66-4c59-ab36-a676dc8aa5ac",
   "metadata": {},
   "source": [
    "&emsp;&emsp;本期公开课，我们将围绕LightGBM算法的基本原理与实战技巧展开讨论，详细解读LightGBM算法原理，以及sklearn API的超参数优化及建模实战应用等。帮助大家快速了解LGBM算法精准高效的真正原因，并学习和掌握算法建模及优化技巧。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248f9f7-f6c0-4043-8031-03be0bfbff0a",
   "metadata": {},
   "source": [
    "- 课程节选自《机器学习实战训练营》正式课程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b946c3-ac67-455f-8690-30636738858f",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/1.jpg\" alt=\"1\" style=\"zoom:20%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537dd23d-bf39-4e24-a626-7cc3effdb965",
   "metadata": {},
   "source": [
    "&emsp;&emsp;公开课内容节选自《机器学习实战训练营》正式课程，正式课程相比公开课，额外增加更具深度和LGBM数学原理推导、LGBM原生API使用和优化技巧，以及基于LGBM原生API的企业级实战案例，公开课与付费正课内容对比如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48efab57-90ac-4523-b137-db41d0e6c11e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/05b61eb9b6792c10ce8c6c221f7d140.png\" alt=\"05b61eb9b6792c10ce8c6c221f7d140\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0eb43-7d22-45dd-94ce-732b2dfc47ef",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果同学希望更进一步进行深度、系统的学习LightGBM及其他机器学习算法，欢迎大家报名《机器学习实战训练营（第六期）》付费正课，课程为130+小时完整体系大课，完整涵盖经典机器学习、集成学习、特征工程、模型融合、特征混合增强和企业级之战案例，总共6大模块，零基础直达机器学习算法岗中高级岗位要求，六年教学经验沉淀，千名学员口碑见证，超值体系大课等你来学！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4165c0-2405-4308-a006-82d9d4c81ce2",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20230215185442588.png\" alt=\"image-20230215185442588\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401736b-192d-4718-b012-9c66a5acb732",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20230215185629296.png\" alt=\"image-20230215185629296\" style=\"zoom:42.5%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c145d-0487-4f15-8ad8-e7c44d219cb5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;除了《机器学习实战训练营》课程外，我们还开设了《数据分析就业班》和《深度学习实战课》，在此查看详细课程介绍和课程大纲：https://appZe9inzwc2314.h5.xiaoeknow.com："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f8cf9-96d4-4288-8dfa-2bf2069da2e7",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20230214180459436.png\" alt=\"image-20230214180459436\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b3125-e2b0-4c35-9e34-086a88feffa8",
   "metadata": {},
   "source": [
    "- **<font color='red'>第六期训练营课程尾单八折特惠进行时！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459efaf-e7e9-416a-bd0b-cd99ea0447ec",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/2.jpg\" alt=\"2\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74f487a-15de-4d2c-9151-77ebc7b34f63",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font size=3><center>扫码添加客服“小可爱”，或者手动添加客服微信：littlecat_1205       \n",
    "    >>>  <font color='red'>**回复“优惠”**</font>抢<font color='red'>**直播间限定折上折**        \n",
    "    **>>>  限量赠送授课老师亲自答疑服务！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df3a94-2721-4739-b6f8-700c120fc053",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/926380675d5976b65f5784be6db5f35.png\" alt=\"926380675d5976b65f5784be6db5f35\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4be06-9f07-4f75-afcb-303899858609",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d5dd1-aa6c-47ec-a425-0576ee183ecc",
   "metadata": {},
   "source": [
    "# <center> LightGBM原理与实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c06fc-f9fb-4572-a3f8-3d4122af2950",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center>Day 1.LightGBM基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476075fd-9b50-4b2f-a8ab-6e06d43f5dee",
   "metadata": {},
   "source": [
    "- LightGBM原理简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb18e3-adac-4851-9489-0fb70a71b234",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LightGBM（Light Gradient Boosting Machine，以下简称LGBM）是一个基于梯度提升决策树（Gradient Boosted Decision Trees，GBDT）的高效、可扩展的机器学习算法，作为GBDT框架的算法的一员，并且作为XGB算法的后来者，LGBM非常好综合了包括XGB在内的此前GBDT算法框架内各算法的一系列优势，并在此基础上做了一系列更进一步的优化。LGBM算法提出的核心目的是为了解决GBDT算法框架在处理海量数据时计算效率低下的问题，而从实践效果来看，LGBM也确实做到了这点——LGBM以牺牲极小的计算精度为代价，将GBDT的计算效率提升了近20倍！这也最终使得LGBM算法是第一个真正意义上能处理海量数据的GBDT框架算法。并且，尽管计算精度存在“选择性的牺牲”，但LGBM的实际建模效果也能达到几乎和XGB同等水平，而且由于LGBM“选择性的牺牲精度”从另一个角度来看其实就是抑制模型过拟合，因此在很多场景下，LGBM的算法效果甚至会好于XGB。种种实践证明，LGBM是一个拥有超高计算效率的同时、又能够保持超高精度的算法，是目前机器学习领域当之无愧的顶级算法之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dccda1-2100-4428-93b8-f98d52ee8fab",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而LGBM是如何做效率和精度“两手抓”的呢？简而言之就是LGBM充分借鉴了XGB提出的一系列提升精度的优化策略，同时在此基础之上进一步提出了一系列的数据压缩和决策树建模流程的优化策略。尽管在算法的数学原理层面LGBM并没有翻越XGB创建的理论高峰，但其提出的一系列优化策略也同样是极具开创性的，其中数据压缩方法能够让实际训练的数据量在大幅压缩的同时仍然保持较为完整的信息，而决策树建模流程方面的优化，则是在XGB提出的直方图优化算法基础上进行了大幅优化，不仅能够加速决策树建模速度，同时也能非常好的处理经过压缩后的数据，从而最终大幅提升每棵树的训练效率（甚至在LGBM提出的一段时间后，新版XGB也采用了LGBM类似的直方图算法来加速建模效率）。并且最重要的是，有理论能够证明，哪怕LGBM实际建模是基于压缩后的数据进行训练，但其预测精度受到的影响也是微乎其微。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7b577-73e5-410f-a0f9-8c18b1dfacf1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，除了算法原理层面的优化方法外，LGBM还提出了非常多针对于实际计算过程的优化，例如Voting Parallel（投票特征并行）方法、特征多线程并行处理方法、GPU加速方法和分布式计算等，这些方法进一步提升了LGBM实际建模效率，并且一定程度拓宽了算法的使用场景。并且需要注意的是，所谓的计算效率优化，不仅体现在计算时间的大幅缩短，同时得益于LGBM所提出的一系列数据压缩技术，使得实际建模时数据内存占用也大幅减少。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17659ff-fdb6-4faa-847a-b2b3a5f6a37e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;总的来说，LGBM算法可以看成是迭代过程几乎全盘借鉴XGB、而在数据压缩方法和决策树训练方法上有大量创新的算法，因此在原理相关内容我们将分为两部分进行讲解，第一部分我们重点介绍LGBM创新性提出的一系列方法，第二部分再来探讨LGBM损失函数求解流程。考虑到LGBM的推导流程和XGB几乎完全一样，原理部分的讲解的重点将会是LGBM创新性提出的一系列数据压缩和优化策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed942c2-600a-4740-9f1a-c49831bb537b",
   "metadata": {},
   "source": [
    "- LightGBM的数据压缩策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc68d67-cec3-4719-86ba-47af46c5e1e1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LightGBM建模过程总共会进行三方面的数据压缩，根据实际建模顺序，会现在全样本上连续变量分箱（连续变量离散化），然后同时带入离散特征和离散后的连续变量进行离散特征捆绑（合并）降维，最终在每次构建一颗树之前进行样本下采样。其中连续变量的分箱就是非常简单的等宽分箱，并且具体箱体的数量可以通过超参数进行人工调节；而离散特征的降维，则是采用了一种所谓的互斥特征捆绑（Exclusive Feature Bundling, EFB）算法，该算法也是由LGBM首次提出，该方法的灵感来源于独热编码的逆向过程，通过把互斥的特征捆绑到一起来实现降维，这种方法能够很好的克服传统降维方法带来的信息大量损耗的问题，并且需要注意的是，输入EFB进行降维的特征，即包括原始离散特征，也包括第一阶段连续变量离散化之后的特征；在这一系列数据压缩之后，LGBM在每次迭代（也就是每次训练一颗决策树模型）的时候，还会围绕训练数据集进行下采样，此时的下采样不是简单的随机抽样，而是一种名为基于梯度的单边采样（Gradient-based One-Side Sampling, GOSS）的方法，和EFB类似，这种方法能够大幅压缩数据，但同时又不会导致信息的大量损失。不难发现，最终输入到每颗决策树进行训练的数据，实际上是经过大幅压缩后的数据，这也是LGBM计算高效的根本原因之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d99cba-cbde-4394-bd7d-e703a0125386",
   "metadata": {},
   "source": [
    "- LightGBM决策树建模优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ee413-482e-41e4-9f7b-f9baf399cdb4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而进入到具体的决策树训练环节，总的来说LGBM采用的决策树建模优化方法有两个，其一是直方图优化算法，这种方法本质上是通过直方图的形式更加高效简洁的表示每次分裂前后数据节点的核心信息，并且父节点和子节点也可以通过直方图减法计算直接算得，从而加速数据集分裂的计算过程:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebdb42c-38d8-4e0f-9387-921221d26247",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303221537628.png\" alt=\"981861843f708f9efb5f74829c336b3\" style=\"zoom: 40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d596568-bc24-4f27-b54e-42c33d74fb96",
   "metadata": {},
   "source": [
    "其二则是leaf wise tree growth的叶子节点优先的决策树生长策略，这其实是一种树生长的模式，对于其他大多数决策树算法和集成算法来说，树都是一次生长一层，也就是所谓的Level-wise tree growth（深度优先的生长策略），生长过程如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b64811-4a70-467e-abe4-b6aea8478aee",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303221541288.png\" alt=\"b4030247c4f8acaee3a8337bb6e7bb2\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5c70d-1cd0-4828-81e8-d13cf3781009",
   "metadata": {},
   "source": [
    "而LGBM则允许决策树生长过程优先按照节点进行分裂，即允许决策树“有偏”的生长，也就是所谓的leaf wise tree growth的叶子节点优先的决策树生长策略，具体生长过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae4cbe-6531-43ed-9c17-569456de56f8",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303221543679.png\" alt=\"33f0d4c90d591b2577698a730d24dfc\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ecf5c-cca0-4f8a-9056-10868941b3a1",
   "metadata": {},
   "source": [
    "根据LGBM论文的论述，但从Level-wise tree growth远离层面，这种方法其实是有利有弊，其优势在于能够大幅提升每颗树的收敛速度，从总体来看相当于是提升了每次迭代效率；而问题则在于会每棵树的计算过程会变得更加复杂，并且存在一定的过拟合风险。不过对于LGBM来说，这些问题都能够被很好的克服，比如计算过程复杂的问题可以通过数据压缩来对冲，而过拟合风险则可以通过限制最大树深度来解决，因此总的来看Level-wise tree growth就是最适合LGBM的决策树生长策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad75ef6-2d42-4328-957b-d1d6b371c87c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们就这些技术逐一来进行介绍，并借助一个精心设计的手动实现的例子，来串联起LGBM在进行Boosting迭代前的全部数据计算流程，借此深化大家对本部分内容的理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a26db-bf68-4310-a7cf-071ad89f545c",
   "metadata": {},
   "source": [
    "### 1.连续变量分箱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdffd73-a425-4c40-8497-800c5075aa87",
   "metadata": {},
   "source": [
    "- 等宽分箱基本概念回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1737567-91e2-4ba9-9e01-5de2c5b75750",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是连续变量分箱。LGBM采用的连续变量分箱方法就是简单的等宽分箱，和我们在特征工程部份介绍的等宽分箱方法无异：首先计算连续变量的取值范围，然后人工输入的max_bin超参数，进行数量为max_bin等宽度的区间划分，并把连续变量的值划归到一个个箱体内部。例如某连续变量取值范围为[0, 10]，max_bin=2，则两个等宽的区间划分为bin0=[0, 5)和bin1=[5, 10]，并且如果某连续变量取值为1，则经过分箱后会被标记为bin0（或者0），如果某各连续变量取值为10，则分箱后会被标记为bin1（或者1）。至此，就将连续变量转化为了离散变量。具体手动实现过程和sklearn实现过程可以回顾特征工程Part 2中的内容介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89284bce-ec84-4026-a3a1-fd1b77d2ec9a",
   "metadata": {},
   "source": [
    "> 这里需要注意，XGB也会对连续变量进行分箱，但XGB的分箱是分位数分箱，而不是等宽分箱。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719ff8c-a8d5-48ce-8968-3bfbfc939854",
   "metadata": {},
   "source": [
    "- 手动示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af6847-2e28-451c-b132-fd0099d2085d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们通过一个手动实现的例子来说明这一过程，需要注意的是，这个手动创建数据集将贯穿本节的各部分内容。数据集基本情况如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c064f4fd-4e66-4ded-8ac5-48f7c1033de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y\n",
       "0  1.2  4.7   1   0  1\n",
       "1  2.9  5.5   1   0  0\n",
       "2  2.6  3.9   0   1  1\n",
       "3  3.3  6.2   1   0  0\n",
       "4  2.0  3.5   1   0  1\n",
       "5  2.5  4.5   1   1  1\n",
       "6  1.4  5.1   1   0  0\n",
       "7  2.1  2.7   0   1  0\n",
       "8  1.7  4.1   1   0  1\n",
       "9  3.0  3.8   1   1  1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(11)\n",
    "\n",
    "x1 = np.array([1.2, 2.9, 2.6, 3.3, 2.0, 2.5, 1.4, 2.1, 1.7, 3.0])\n",
    "x2 = np.array([4.7, 5.5, 3.9, 6.2, 3.5, 4.5, 5.1, 2.7, 4.1, 3.8])\n",
    "x3 = np.random.randint(0, 2, 10)\n",
    "x4 = np.random.randint(0, 2, 10)\n",
    "y = np.array([1, 0, 1, 0, 1, 1, 0, 0, 1, 1])\n",
    "data = pd.DataFrame({'x1':x1, 'x2':x2, 'x3':x3, 'x4':x4, 'y':y})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d750c1-48b0-4f86-b0cb-2db2b8387fde",
   "metadata": {},
   "source": [
    "数据集总共包含10条数据，其中x1和x2是连续特征，x3和x4是离散特征，y是标签，该数据集是各二分类数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45fd5c-d1c1-470e-9780-29c441741da0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们对其中的连续变量进行分箱，这里我们设置max_bin=2，即进行两个箱体的等宽分箱。具体实现过程及分箱结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2092e5e6-ec13-4bd4-84f2-c9eabce9a23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x1   x2  x3  x4  y  x1_binned  x2_binned\n",
      "0  1.2  4.7   1   0  1        0.0        1.0\n",
      "1  2.9  5.5   1   0  0        1.0        1.0\n",
      "2  2.6  3.9   0   1  1        1.0        0.0\n",
      "3  3.3  6.2   1   0  0        1.0        1.0\n",
      "4  2.0  3.5   1   0  1        0.0        0.0\n",
      "5  2.5  4.5   1   1  1        1.0        1.0\n",
      "6  1.4  5.1   1   0  0        0.0        1.0\n",
      "7  2.1  2.7   0   1  0        0.0        0.0\n",
      "8  1.7  4.1   1   0  1        0.0        0.0\n",
      "9  3.0  3.8   1   1  1        1.0        0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# 将 x1 和 x2 分别进行等宽分箱，分成 2 个箱子\n",
    "n_bins = 2\n",
    "strategy = 'uniform'\n",
    "\n",
    "kbins_x1 = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy=strategy)\n",
    "kbins_x2 = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy=strategy)\n",
    "\n",
    "x1_binned = kbins_x1.fit_transform(data['x1'].values.reshape(-1, 1))\n",
    "x2_binned = kbins_x2.fit_transform(data['x2'].values.reshape(-1, 1))\n",
    "\n",
    "# 将分箱后的结果保存到原始数据集中\n",
    "data['x1_binned'] = x1_binned\n",
    "data['x2_binned'] = x2_binned\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46771ae-947a-4c7b-b44a-b528efe5ceec",
   "metadata": {},
   "source": [
    "至此，我们就完成了LGBM的第一阶段数据处理——连续变量的分箱处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0943ab-8d49-44f1-954f-414628f85bfb",
   "metadata": {},
   "source": [
    "### 2.互斥特征捆绑（Exclusive Feature Bundling，EFB）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f3a11-7a16-4518-89e7-29d6d3ce1d7d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来则是围绕这些离散特征进行降维。LGBM采用了一种名为互斥特征捆绑（Exclusive Feature Bundling，EFB）的降维方法，这种方法在LGBM论文LightGBM: A Highly Efficient Gradient Boosting Decision Tree (2017)中首次提出，不同于第一阶段的简单的等宽分箱，EFB实际计算过程非常复杂，我们这里从EFB方法提出背景、计算原理和手动示例三个方面对其进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a5c15-d54a-49a6-bb1e-cb870dd19ec2",
   "metadata": {},
   "source": [
    "#### 2.1 EFB算法简介与基本流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1fece-7a65-477e-bc71-c1169ee00d26",
   "metadata": {},
   "source": [
    "- EFB算法提出背景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cee3bf-b710-4444-90ee-a9366d9a973c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据LightGBM: A Highly Efficient Gradient Boosting Decision Tree (2017)论文描述，原始的GBDT在进行每颗树的训练时，需要带入全部数据来进行信息增益的计算，从而寻找到决策树生长过程中的最佳切分点，这个过程也就是所谓的扫描全部数据来决定切分点的过程。这个过程尽管非常精准，但计算复杂度非常高（直接和特征数量及样本数量成正比），在进行海量数据建模训练的时候会耗费大量的算力和时间。因此，为了能够更好的应对海量数据的模型训练，样本采样和特征降维是非常必要的。但传统的方法在这方面往往效果不佳，例如简单的欠采样（样本随机抽样）可能会造成模型训练过程非常不稳定，而PCA降维则只适用于处理冗余特征，当每个特征都具有相当信息体量时强行进行降维则会导致信息大量丢失。为了解决这个问题，LGBM开创性的提出了基于梯度的单边采样方法（GOSS）进行样本数量的压缩，提出了互斥特征捆绑方法（EFB）来进行特征压缩。不同于以往的方法，GOSS和EFB能够非常好的兼顾预测精度与计算效率。此外，对连续变量进行离散化也是非常有效的数据压缩的手段，LGBM在XGB提出的直方图优化的基础上，进一步提出了一种改进策略，和GOSS和EFB类似，这种LGBM直方图优化方法同样能够在大幅提高计算效率的同时保证预测精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7806451a-b210-45bc-b9b7-7b354ba8194f",
   "metadata": {},
   "source": [
    "- 简化后的EFB计算流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab610c-922b-4e58-b12b-d7dcb13774a3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而具体到EFB降维算法，其实是受到独热编码启发，设计的类似于独热编码逆向过程的一种算法。例如一组数据情况如下，独热编码是从左往右的计算过程，把一列展开为多列，而EFB则是从右往左进行计算，将多列压缩为一列："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25e7c1-f853-47c6-9ed0-b25aa2417ce3",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303222002280.png\" alt=\"0be767e9953d7db2a66752f524e6ba4\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24df5f8-b1b9-4e63-b3d6-7c5d0eaec2cc",
   "metadata": {},
   "source": [
    "> 具体独热编码的相关内容，可回顾特征工程Part 2数据重编码部分内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20210c96-a196-4088-b4ce-6300cf72290e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那既然是独热编码的逆向计算，我们就需要首先讨论为什么LGBM不需要独热编码。我们知道，独热编码本质上是对离散特征更加细粒度的信息呈现，在某些场景下能够提升模型效果。当然更重要的是独热编码能够非常好的用于表示离散变量，对于大多数无法区分连续变量和离散变量的机器学习算法来说，通过独热编码重编码的数据将能够非常方便进行例如离散变量之间的距离计算等操作。但是这些独热编码的优势对于LGBM来说并不存在。首先LGBM带入模型计算的全部变量都是离散变量（连续变量也会被离散化），其次独热编码带来的更细粒度的信息呈现也不会进一步提升模型效果（对于大多数集成学习算法来说都是如此），当然更重要的是，LGBM的算法设计就是为了处理海量高维数据，独热编码只会进一步造成维度灾难。因此，LGBM不仅不需要进行独热编码，还需要进行独热编码的逆操作来进行特征降维。当然，我们这里只是借用独热编码的计算过程帮大家理解EFB的降维过程，在实际计算过程中，EFB的降维的目标并不是把独热编码之后的特征再转换回来，而是找到那些原始状态下就存在类似上图中x1和x2这种关系的特征，来将其合成为一个特征。这里我们注意观察，上图中x1和x2两个特征存在一种这样的关系——任何一条样本都不会同时在x1和x2上取值非0，在EFB原理的定义中，这种关系的特征又被称作互斥特征，而互斥特征其实是可以合成一个特征的，比如上图中的x，这个合成的过程并不会有任何的信息损失，而合成的过程又被称作特征捆绑。这也就是所谓的互斥特征捆绑算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bcee4c-67ae-488c-b18e-74323327a946",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们这里再看一个互斥特征捆绑的例子，比如如下x3和x4，也是互斥的，此时我们可以将x3和x4捆绑为一个新的x_b1特征，新特征中可以用0、1、2来表示x3和x4的不同组合，从而在不损失信息的情况下，进行了降维。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f98ee-d26d-4cc1-8953-3182ae5f7dfa",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303222003609.png\" alt=\"6a6d2ee962754f94b7232cb069835ce\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106045a-17d4-4fc7-b68c-a5bc7301fe33",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，这只是一个简化后的示例，真实的EFB特征降维情况会非常复杂，并不是简单的将多个离散变量的不同取值组合进行重新赋值，这个例子只是用于帮大家建立对EFB的感性的认识，接下来我们就围绕原论文中提出的EFB算法来进行更加严谨的算法流程介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b67c9-7ce5-47fe-aff3-6a1a8e48d966",
   "metadata": {},
   "source": [
    "#### 2.2 EFB算法基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b944f64-cef6-4fd8-b258-81455a19a8b8",
   "metadata": {},
   "source": [
    "- 放宽互斥的条件：冲突比例（conflict_rate）概念介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca5727-b9e2-4b65-b38d-316cc02f5d8c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;真实数据的EFB计算过程会非常复杂，首先是关于“互斥”关系的定义，EFB并不是只压缩完全互斥的特征，而是非常灵活的定义了一个冲突比例（又称非互斥比例），这个比例用于表示两个特征中冲突（即非互斥、同时取非零值）的取值占比，来衡量两个特征互斥程度。当然，冲突比例越大说明互斥程度越低。例如对于如下数据集，总共包含四条数据，其中只有第四条数据是同时取得了非零值，因此只有一条数据是冲突的，其他数据都是互斥的，因此冲突比例为1/4=0.25："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f0245-c6d6-47c6-8192-3316711b22a0",
   "metadata": {},
   "source": [
    "|特征1|特征2|      \n",
    "|:--:|:--:|\n",
    "|0|1|\n",
    "|1|0|\n",
    "|0|1|\n",
    "|1|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee442d06-d871-436f-94d6-9ecedf0c2796",
   "metadata": {},
   "source": [
    "而如果数据集如下，此时两个特征非同时为0的（非全零样本）数量为3，则冲突比例为1/3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674c560-b9b7-42a1-bd2d-1f8bc0f23df3",
   "metadata": {},
   "source": [
    "|样本情况|特征1|特征2|      \n",
    "|:--:|:--:|:--:|\n",
    "|非全零样本|0|1|\n",
    "|非全零样本|1|0|\n",
    "|全零样本|0|0|\n",
    "|非全零样本|1|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2c8bb-e0d6-40e7-81d9-516c4684098f",
   "metadata": {},
   "source": [
    "同时，LGBM提供了一个名为max_conflict_rate的超参数，用于表示最大冲突比例，当两个特征的冲突比例小于我们设置的最大冲突比例（max_conflict_rate）时，我们就认为这两个特征并不冲突，而是互斥的，是可以进行捆绑的。例如假设我们设置max_conflict_rate=0.3，则上述两个特征可以进行捆绑，而如果我们设置max_conflict_rate=0.2，则上面两个特征超过了我们认为冲突的阈值，因此这两个特征是冲突的，而不是互斥的，是不能进行进一步捆绑的。很明显，max_conflict_rate设置的越小，对互斥的要求就越高，特征就越不容易被捆绑，模型计算量就越大、精度也越高，而如果max_conflict_rate设置的很大，则更多的特征会被捆绑，模型计算速度会更快，但精度也会降低。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0a817-0255-4615-b824-953896bf56d3",
   "metadata": {},
   "source": [
    "- 借助图着色(Graph Coloring Problem)问题来解决特征捆绑流程问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea040c17-bbd4-418e-8c0d-7ef5dcd9f4ae",
   "metadata": {},
   "source": [
    "&emsp;&emsp;通过最大冲突比例的概念引入，相当于是放宽的互斥的条件，或者说给是否互斥添加了一个可以量化计算的阈值。而真正开始进行特征捆绑的时候，面对海量特征，LGBM是如何进行EFB计算的呢？实际上LGBM会将特征捆绑问题视作（或者说是转化为）一个图着色的问题(Graph Coloring Problem)。图着色问题一种经典的组合优化问题，其问题描述为：给定一个无向图，如何用尽量少的颜色对图中的每个顶点进行着色，使得相邻的顶点颜色不同。这里的“颜色”可以是任意一种符号或编号，只要保证相邻的顶点颜色不同即可。在EFB计算过程中，会将不同特征视作图上的一个个点，若特征之间存在冲突，则用一条无向边进行连接，边的权重就是冲突比例，而如果两个特征互斥，则彼此没有边进行相连。而在将特征及其冲突情况用图进行展示后，即可进一步进行图着色——即在相邻的点颜色不同的前提条件下，用尽可能少的颜色对图上的点进行着色，既然相互冲突的特征都有边进行相连，那么相同颜色的点其实就是互斥的特征，接下来我们仅需把相同颜色的特征进行合并即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df68255-4935-464c-882c-48117001705f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，这个过程听起来较为抽象，我们这里还是以上面的data数据集为例，来展示一个借助图着色来进行特征捆绑的完整过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e96e3a-fa66-4cb6-addb-59275e82c1ff",
   "metadata": {},
   "source": [
    "#### 2.3 EFB算法计算流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c61272-c82f-4be6-8356-ad97ea4cfc21",
   "metadata": {},
   "source": [
    "- 计算冲突比例矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998ee68-10fb-4094-861f-fef0cf0978e3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;经过连续变量离散化，现在我们的data数据就已经变成了四个离散特征的数据集，四个离散特征分别为：'x1_binned'、'x2_binned'、'x3'、'x4'："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81ef3d00-7906-4ebf-a804-7a7dae912dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned\n",
       "0  1.2  4.7   1   0  1        0.0        1.0\n",
       "1  2.9  5.5   1   0  0        1.0        1.0\n",
       "2  2.6  3.9   0   1  1        1.0        0.0\n",
       "3  3.3  6.2   1   0  0        1.0        1.0\n",
       "4  2.0  3.5   1   0  1        0.0        0.0\n",
       "5  2.5  4.5   1   1  1        1.0        1.0\n",
       "6  1.4  5.1   1   0  0        0.0        1.0\n",
       "7  2.1  2.7   0   1  0        0.0        0.0\n",
       "8  1.7  4.1   1   0  1        0.0        0.0\n",
       "9  3.0  3.8   1   1  1        1.0        0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f2e59e8-5779-4c7d-b76f-3dda19f18623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1_binned  x2_binned  x3  x4\n",
       "0        0.0        1.0   1   0\n",
       "1        1.0        1.0   1   0\n",
       "2        1.0        0.0   0   1\n",
       "3        1.0        1.0   1   0\n",
       "4        0.0        0.0   1   0\n",
       "5        1.0        1.0   1   1\n",
       "6        0.0        1.0   1   0\n",
       "7        0.0        0.0   0   1\n",
       "8        0.0        0.0   1   0\n",
       "9        1.0        0.0   1   1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['x1_binned', 'x2_binned', 'x3', 'x4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e65a5b-eeff-4384-a04f-286695b80b94",
   "metadata": {},
   "source": [
    "然后我们需要计算这四个特征彼此之间的冲突比例，我们可以通过定义如下函数来完成计算。该函数定义了多个特征彼此之间冲突比例矩阵的计算过程，这里的冲突比例矩阵就类似于相关系数矩阵，用于表示多个特征彼此之间冲突比例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bc98d9b-5e35-4cad-ae27-7113aba74703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conflict_ratio_matrix(data):\n",
    "    \"\"\"\n",
    "    冲突比例计算函数\n",
    "    \n",
    "    :param data: 计算冲突比例的dataframe\n",
    "    :return:冲突比例矩阵\n",
    "    \"\"\"\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.values\n",
    "\n",
    "    num_features = data.shape[1]\n",
    "    # 创建空特征比例矩阵\n",
    "    conflict_matrix = np.zeros((num_features, num_features))\n",
    "\n",
    "    # 两层循环挑选两个特征\n",
    "    for i in range(num_features):\n",
    "        for j in range(i+1, num_features):\n",
    "            # 计算特征冲突特征总数\n",
    "            conflict_count = np.sum((data[:, i] != 0) & (data[:, j] != 0))\n",
    "            # 计算不为0的特征总数\n",
    "            total_count = np.sum((data[:, i] != 0) | (data[:, j] != 0))\n",
    "            # 计算冲突比例\n",
    "            conflict_ratio = conflict_count / total_count\n",
    "            conflict_matrix[i, j] = conflict_ratio\n",
    "            conflict_matrix[j, i] = conflict_ratio\n",
    "\n",
    "    return conflict_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2686dd5a-c01a-40d5-bad2-de86366e8e94",
   "metadata": {},
   "source": [
    "然后尝试带入四个离散变量，进行冲突比例的计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5178ade5-f92f-487a-8307-9ae37342a567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.42857143, 0.44444444, 0.5       ],\n",
       "       [0.42857143, 0.        , 0.625     , 0.125     ],\n",
       "       [0.44444444, 0.625     , 0.        , 0.2       ],\n",
       "       [0.5       , 0.125     , 0.2       , 0.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_ratio_matrix(data[['x1_binned', 'x2_binned', 'x3', 'x4']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1febbe0d-45ef-45b7-80df-63f93506f7a3",
   "metadata": {},
   "source": [
    "其中，矩阵中的第(i, j)个元素代表第i个特征和第j个特征的冲突比例，例如(1, 2)=0.42857表示第一个特征和第二个特征冲突比例为0.42857。能够看出，这四个特征中并不存在没有冲突（即互斥）的特征，只能看到2、4和3、4特征冲突比例较小："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad941f81-b3c0-431e-80df-d593752d89f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1_binned  x2_binned  x3  x4\n",
       "0        0.0        1.0   1   0\n",
       "1        1.0        1.0   1   0\n",
       "2        1.0        0.0   0   1\n",
       "3        1.0        1.0   1   0\n",
       "4        0.0        0.0   1   0\n",
       "5        1.0        1.0   1   1\n",
       "6        0.0        1.0   1   0\n",
       "7        0.0        0.0   0   1\n",
       "8        0.0        0.0   1   0\n",
       "9        1.0        0.0   1   1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['x1_binned', 'x2_binned', 'x3', 'x4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd1887-83d4-4d76-8bf0-e251de2da206",
   "metadata": {},
   "source": [
    "- 图展示与着色"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8dc79f-a1c5-46ed-916c-7b9aaa36433a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后我们将冲突比例矩阵转化为如下所示的图，即不同的点代表着不同的特征，而如果两个特征存在冲突，则两个点之间构建一条无向边，边的权重就是冲突比例："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7477c0-a176-4aa7-ae40-8ea8607a4a32",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303231529895.png\" alt=\"1679556539065\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aecd2f5-6660-4b22-a90e-0d741c98e962",
   "metadata": {},
   "source": [
    "当然，关于是否互斥，其实可以通过max_conflict_rate进行调节，我们假设max_conflict_rate=0.3，则上图中x3和x4、x2_binned和x4的冲突比例小于0.3，所以这两组特征是互斥的，我们可以将连接这两组特征的边删除，删除后的图如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5cf41-3fbc-42af-85ff-c081b5c0a275",
   "metadata": {},
   "source": [
    "> 这里需要注意，这里我们设置的max_conflict_rate=0.3只是用于当前例子展示所用。真实情况下max_conflict_rate的取值建议设置为0.1或者更小的数，以确保模型精度。相关超参数取值推荐会在本章课程的最后进行讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da562a-35b5-4545-a7e1-09b839ba8c3b",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303231538803.png\" alt=\"1679557086174\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce728aa-936c-4239-907a-6a4f593eede0",
   "metadata": {},
   "source": [
    "在完成图转化之后，接下来我们将特征捆绑问题视作一个图着色的问题，即需要用最少的颜色对图上的四个点进行着色，并要求相邻的点（彼此有线段连接的点）颜色不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64994016-f374-4dd0-b77d-dd78d0215def",
   "metadata": {},
   "source": [
    "&emsp;&emsp;具体着色的流程是会先从度（边的个数，也被成为degree）更大的点进行着色，例如上图中的四个点的degree如图所示，很明显x1_binned的度最大，然后是x2_binned和x3，这里我们先将x1_binned着色为红色（颜色可以随机选取），然后由于x3和x2_binned彼此相连，并且都和x1_binned相连，因此x3和x2_binned颜色不能相同，且不能和x1_binned相同，因此这里分别给x3和x2_binned着色为黄色和绿色，最后是x4，由于x4和x1_binned相连，所以x4不能用红色，而x4和x3、x2_binned没有相连，并且为了图上出现的颜色尽可能少，所以x4可以用绿色或者黄色，考虑到x4和x2_binned冲突比例较小，互斥程度较大，因此可以给x4使用绿色，最后着色结果如上图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc397d3-2670-4788-88d1-d94c2488be0a",
   "metadata": {},
   "source": [
    "- 特征捆绑过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4946e-d7f4-484c-a1e2-56a8c947142e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，我们把相同着色的点（特征）进行捆绑。捆绑过程并不复杂，核心是需要对特征取值进行合理转化。而具体的转化过程中，LGBM会根据主特征的最大取值设置一个offset值，然后对合并进来特征的非零值加上这个offset值，然后再让这两个特征取值相加。例如data数据集中，我们将x4并入x2_binned中，则offset=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aabaf534-50dc-40a5-8674-a3c335671795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "5    1.0\n",
       "6    1.0\n",
       "7    0.0\n",
       "8    0.0\n",
       "9    0.0\n",
       "Name: x2_binned, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x2_binned']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83baddb-b7bc-4a71-91f8-3386ec49d840",
   "metadata": {},
   "source": [
    "然后对x4的非零值+offset，并构成新的特征'x2_binned&x4'具体计算过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce91760c-8336-4256-a136-c9e7766fd402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0, 2, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(data['x4'])\n",
    "arr[arr != 0] += 1\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e6b88a9-98b7-4bba-8f29-908d2b2dc81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned  x2_binned&x4\n",
       "0  1.2  4.7   1   0  1        0.0        1.0           1.0\n",
       "1  2.9  5.5   1   0  0        1.0        1.0           1.0\n",
       "2  2.6  3.9   0   1  1        1.0        0.0           2.0\n",
       "3  3.3  6.2   1   0  0        1.0        1.0           1.0\n",
       "4  2.0  3.5   1   0  1        0.0        0.0           0.0\n",
       "5  2.5  4.5   1   1  1        1.0        1.0           3.0\n",
       "6  1.4  5.1   1   0  0        0.0        1.0           1.0\n",
       "7  2.1  2.7   0   1  0        0.0        0.0           2.0\n",
       "8  1.7  4.1   1   0  1        0.0        0.0           0.0\n",
       "9  3.0  3.8   1   1  1        1.0        0.0           2.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x2_binned&x4'] = arr + data['x2_binned']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a7077-2626-4a29-9dd0-6cecd3beee20",
   "metadata": {},
   "source": [
    "至此，我们就在data这个简化的数据集上完成了EFB特征捆绑过程，经过连续变量分箱和特征捆绑，实际上接下来带入进行模型训练的特征就只有x1_binned、x2_binned&x4和x3这三个特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdae9f27-5146-4959-89f9-102d6d38ca58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1_binned  x2_binned&x4  x3\n",
       "0        0.0           1.0   1\n",
       "1        1.0           1.0   1\n",
       "2        1.0           2.0   0\n",
       "3        1.0           1.0   1\n",
       "4        0.0           0.0   1\n",
       "5        1.0           3.0   1\n",
       "6        0.0           1.0   1\n",
       "7        0.0           2.0   0\n",
       "8        0.0           0.0   1\n",
       "9        1.0           2.0   1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['x1_binned', 'x2_binned&x4', 'x3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d0e78-4f30-435a-9526-b9368f24a77b",
   "metadata": {},
   "source": [
    "### 3.基于梯度的单边采样（Gradient-based One-Side Sampling，GOSS）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd83be-ea33-4e5f-b82e-e571362b6640",
   "metadata": {},
   "source": [
    "#### 3.1 GOSS计算基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5724c-1c1d-47b4-9b2d-b05e2bd858d4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先来看基于梯度的单边采样（Gradient-based One-Side Sampling）方法，也就是所谓的GOSS抽样方法。不同于简单随机抽样，GOSS是一种非常特殊的基于梯度分布的抽样方法。我们知道在执行优化算法的过程中，每个样本都有一个对应的梯度计算结果，如果某条样本梯度绝对值较小，则说明这条样本已经被正确的分类或者预测结果和真实结果非常接近，在后续的参数更新过程中，这些梯度绝对值较小的样本对参数的改进贡献较小，因此每次迭代计算时再把这些小梯度的样本再算一遍梯度，会一定程度造成资源浪费。而反观那些梯度绝对值较大的样本，这些样本具有更高的误差，因此对模型的训练有更大的贡献。因此GOSS的思路是将全部样本按照梯度绝对值大小进行降序排序，然后抽取梯度绝对值最大的前$a\\%$的样本，然后把其他样本都视作小梯度样本，并从这些小梯度样本中随机抽取$b\\%$个样本，而这些大梯度样本和随机抽取的小梯度样本，就构成了接下来模型训练的数据集。而只针对小梯度样本（一边）进行抽样、保留（另一边）全部大梯度样本，也就是单边采样一词的由来。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81aa87-92fc-4a4d-95ba-ef0489e2bbc6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而在具体执行GOSS的时候有以下几点需要注意：         \n",
    "\n",
    "- 1.GOSS计算过程是根据梯度的绝对值大小进行样本划分和抽样，并不是样本梯度的真实值；\n",
    "\n",
    "- 2.GOSS中样本选取比例，也就是梯度绝对值最大的前$a\\%$和小样本中随机抽样的$b\\%$，实际上都是超参数，可以在建模过程中灵活调节。这里的$a\\%$可以换成更专业的超参数名称：top_rate，而小样本抽取的$b\\%$更专业的名称则是other_rate；     \n",
    "\n",
    "- 3.我们知道样本梯度是基于预测结果计算而来的（具体来说是损失函数的一阶导数），而在第一棵树构建之前我们就需要进行GOSS采样，此时还没有模型预测结果，梯度计算依据的是LGBM的初始预测值，和其他集成学习类似，LGBM的初始预测值也是根据损失函数的不同类型计算得到的结果；\n",
    "\n",
    "- 4.由于每次迭代都会更新模型参数，因此每次建树之前都会重新进行抽样，而除非人为控制迭代过程（例如使用一种非常特殊的Booster API，后面会详细介绍），否则一般来说top_rate和other_rate设置好了就不会再发生变化；     \n",
    "\n",
    "- 5.关于top_rate和other_rate的数值设置，一般来说top_rate越大other_rate越小，则模型过拟合风险就越大，反之则模型学习能力会被限制，而如果这两个参数同时较大，则会增加模型训练复杂度，增加模型训练时间。关于这组参数，并没有一个普遍适用的取值，还是需要根据实际情况进行超参数优化。\n",
    "\n",
    "- 6.尽管带入训练的数据是GOSS抽样后的数据，但在后续决策树生长的过程中，小梯度样本的梯度（和损失函数二阶导数）会再乘以一个大于1的膨胀系数，再和大梯度样本的梯度（和损失函数二阶导数）进行相加，构成一个数据集的梯度（和损失函数二阶导数），来指导后续的迭代进行。而之所以要让小梯度样本进一步膨胀再加入到样本数据梯度中，其实也是为了尽可能还原原始真实的数据集梯度。也即是说，GOSS抽样并不是想要改变数据集梯度，而是希望通过更小的计算量，来尽可能还原原始数据集完整梯度，以此来提升建模的精确度，其基本过程可以由下图进行表示：<img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303231809934.png\" alt=\"5a9d29da9104eae4106ca796a7a493c\" style=\"zoom:50%;\" />具体膨胀系数如何计算，其实也并不复杂，就是$\\frac{1-a}{b}$，或者说是$\\frac{1-top\\_rate}{other\\_rate}$。例如当top_rate=0.1，other_rate=0.2时，小样本梯度膨胀系数为：$\\frac{1-top\\_rate}{other\\_rate}=\\frac{1-0.1}{0.2}=4.5$。最终样本梯度=大样本梯度+小样本梯度*4.5算得。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e5005-c9ce-4ccf-af33-330bea2714cd",
   "metadata": {},
   "source": [
    "- 7.GOSS过程带来的误差：最后需要注意的是，尽管GOSS抽样后我们通过膨胀系数来尽可能还原数据集整体的梯度，但这种还原肯定是存在一定误差的。根据原论文描述，这种误差可以通过如下公式进行表示：<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202304091801639.png\" alt=\"1681034491832\" style=\"zoom:50%;\" /></center><br>原论文中的公式并不好理解，这里我们可以将其等价为另一个公式进行解释。首先，假设我们有一个样本集合$I$，其中有$|I|$个样本。对于一个梯度值阈值$a$，我们将样本集合$I$划分为两个子集$I_{large}$和$I_{small}$。$I_{large}$包含所有梯度值大于等于$a$的样本，而$I_{small}$包含所有梯度值小于$a$的样本。用$|I_{large}|$表示$I_{large}$中的样本数量，用$|I_{small}|$表示$I_{small}$中的样本数量。接下来，我们从$I_{small}$中随机采样一定比例（$\\alpha$）的样本，则梯度计算的最大误差估计为：$$\\mathrm{Error} = \\frac{1}{|I|}\\sum_{i \\in I_{large}} g_i - \\frac{1 - \\alpha}{\\alpha |I_{small}|}\\sum_{i \\in I_{small}} g_i$$这里，$g_i$表示第$i$个样本的梯度值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca2b6d-a8b4-4bbe-aa73-bafd19da212a",
   "metadata": {},
   "source": [
    "#### 3.2 GOSS计算过程实例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889cab7-186a-43aa-aa3e-ecbaf83c4c72",
   "metadata": {},
   "source": [
    "- 损失函数、梯度与Hessian计算公式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c803f-eca6-4642-81cd-a1057eaca5ff",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们继续借助简单示例数据集data来执行一次完整的GOSS采样计算过程。由于GOSS采样计算过程会涉及样本梯度计算，因此这里我们首先需要回顾样本梯度的计算方法。我们知道样本梯度是损失函数在各参数方向上求导得到的结果，因此梯度实际上和损失函数相关。这里data数据集是二分类数据集，因此假设建模过程中的损失函数是二分类交叉熵损失函数，在Lesson 4介绍梯度下降算法时，我们就介绍了二分类交叉熵损失函数的计算公式，以及样本梯度的计算方法，并借助手写代码来进行实现，这里我们快速回顾下交叉熵损失计算公式，对于第i条样本来说，$y_i$是真实标签，而$\\hat y_i$或者$p_i$是概率预测结果，则样本整体二分类交叉熵损失计算公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5817ae-b16c-4ed0-bcf3-d605f1b3e79a",
   "metadata": {},
   "source": [
    "$$\\mathcal{L}=-\\frac{1}{n} \\sum_{i=1}^{n}\\left[y_{i} \\log p_{i}+\\left(1-y_{i}\\right) \\log \\left(1-p_{i}\\right)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25c91c-5b70-4d97-b1d6-c2b10ca9ad42",
   "metadata": {},
   "source": [
    "此时第$i$条样本的梯度就是损失函数对预测样本的一阶偏导数："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca58944-4769-4fc2-a19a-d6e10afc1230",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial \\mathcal{L}}{\\partial p_{i}}=\\frac{1-y_{i}}{1-p_{i}}-\\frac{y_{i}}{p_{i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4940e-8c8e-4ecd-bdee-3e5dbe89e481",
   "metadata": {},
   "source": [
    "更进一步的，由于后续直方图计算过程还需要用到损失函数的二阶偏导数，也就是所谓的Hessian矩阵（值），也被称作黑塞矩阵、海森矩阵等。对于第$i$条样本，损失函数的二阶偏导数计算公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70800feb-266a-437a-80f5-8c20130c27c8",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial^{2} \\mathcal{L}}{\\partial p_{i}^{2}}=\\frac{y_{i}}{p_{i}^{2}}+\\frac{1-y_{i}}{\\left(1-p_{i}\\right)^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5f120-f005-4659-987f-580854514440",
   "metadata": {},
   "source": [
    "并且，为了方便后续计算，我们可以编写函数来进行损失函数、梯度和Hessian值的计算。其中二分类交叉熵损失可以按照如下方式进行计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e50057-f8f7-4054-93ae-8806f4e327ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算二分类交叉熵损失函数\n",
    "    :param y_true: 真实标签，一个 Numpy 数组，形状为 (n_samples,)\n",
    "    :param y_pred: 预测标签，一个 Numpy 数组，形状为 (n_samples,)\n",
    "    :return:二分类交叉熵损失值，一个标量\n",
    "    \"\"\"\n",
    "    # 确保输入的标签为 0 或 1\n",
    "    y_true = np.clip(y_true, 1e-7, 1-1e-7)\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1-1e-7)\n",
    "    # 计算二分类交叉熵损失\n",
    "    loss = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ade5f2-ea25-4d33-b324-d587be869329",
   "metadata": {},
   "source": [
    "这里的np.clip函数是用于将输出结果限制在一个范围内，避免出现零值相除的情况（sklearn中用于实现相同功能的log_loss函数也是采用类似的处理方法）。而每条样本的梯度计算函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb24679-6cfa-414c-bc79-397d968daaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_grad(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算二分类交叉熵损失函数的一阶导数\n",
    "    :param y_true: 真实标签，一个 Numpy 数组，形状为 (n_samples,)\n",
    "    :param y_pred: 预测标签，一个 Numpy 数组，形状为 (n_samples,)\n",
    "    :return:二分类交叉熵损失函数的一阶导数，一个 Numpy 数组，形状为 (n_samples,)\n",
    "    \"\"\"\n",
    "    # 确保输入的标签为 0 或 1\n",
    "    y_true = np.clip(y_true, 1e-7, 1-1e-7)\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1-1e-7)\n",
    "    # 计算二分类交叉熵损失函数的一阶导数\n",
    "    grad = (1 - y_true) / (1 - y_pred) - y_true / y_pred\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61255f87-9efe-41e7-ac25-fe422e52a508",
   "metadata": {},
   "source": [
    "每条样本的Hessian值计算函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebdfd34d-f102-4dee-a7ad-92fe0ac24674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_hess(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算二分类交叉熵损失函数的二阶导数\n",
    "    :param y_true: 真实标签，一个 Numpy 数组，形状为 (n_samples,)\n",
    "    :param y_pred: 预测标签，一个 Numpy 数组，形状为 (n_samples,)\n",
    "    :return: 生成的特征张和标签张量：二分类交叉熵损失函数的二阶导数，一个 Numpy 数组，形状为 (n_samples,)\n",
    "    \"\"\"\n",
    "    # 确保输入的标签为 0 或 1\n",
    "    y_true = np.clip(y_true, 1e-7, 1 - 1e-7)\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    # 计算二分类交叉熵损失函数的二阶导数\n",
    "    hess = y_true / (y_pred ** 2) + (1 - y_true) / ((1 - y_pred) ** 2)\n",
    "    return hess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a17a7a5-4cc0-420c-ae62-b26ea6790298",
   "metadata": {},
   "source": [
    "有了这些函数定义后，接下来我们来查看当前数据集在首次建模之前的梯度值如何计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc6257-3ac5-4327-a05f-e5d2a4da2f16",
   "metadata": {},
   "source": [
    "- LGBM初始预测值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc070e0-2e1c-42f5-8efc-77cc8d2b280d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;正如此前所说，首次进行GOSS抽样时梯度计算依据是LGBM算法的初始预测值，如果是交叉熵损失函数，则初始预测值为1类样本占比（或者1类样本总数）的对数几率（log odds）计算结果，并且每条样本初始预测值都相同，具体计算过程可以由如下计算公式表示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4354861-4dd8-436b-a724-fb01e8a9bf80",
   "metadata": {},
   "source": [
    "$$\\hat y = ln\\frac{p}{1-p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83256729-09be-4ed5-8aec-5ace893b1d2d",
   "metadata": {},
   "source": [
    "其中$p$为1类的占比（或者1类总数，计算结果都相同）。例如对于data数据集来说，初始预测值可以按照如下方式进行计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6aa173-b373-4d47-a9b3-dd9494f7122a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned  x2_binned&x4\n",
       "0  1.2  4.7   1   0  1        0.0        1.0           1.0\n",
       "1  2.9  5.5   1   0  0        1.0        1.0           1.0\n",
       "2  2.6  3.9   0   1  1        1.0        0.0           2.0\n",
       "3  3.3  6.2   1   0  0        1.0        1.0           1.0\n",
       "4  2.0  3.5   1   0  1        0.0        0.0           0.0\n",
       "5  2.5  4.5   1   1  1        1.0        1.0           3.0\n",
       "6  1.4  5.1   1   0  0        0.0        1.0           1.0\n",
       "7  2.1  2.7   0   1  0        0.0        0.0           2.0\n",
       "8  1.7  4.1   1   0  1        0.0        0.0           0.0\n",
       "9  3.0  3.8   1   1  1        1.0        0.0           2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574a1f54-71de-4fd6-9849-81ee0c373e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始预测值： 0.4054651081081642\n"
     ]
    }
   ],
   "source": [
    "# 计算每个类别的频率\n",
    "class_freq = data['y'].value_counts(normalize=True)\n",
    "\n",
    "# 计算初始预测值\n",
    "initial_prediction = np.log(class_freq[1] / class_freq[0])\n",
    "\n",
    "print(\"初始预测值：\", initial_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cc6e62c-4f12-48d9-aba0-c07eb1345e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.6\n",
       "0    0.4\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5953d10a-64f1-4a49-a354-96cd08760150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_freq[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41a1d4-652d-45d5-81a4-c5339dd79a4d",
   "metadata": {},
   "source": [
    "因此所有样本的初始预测结果为0.4，将其添加到data的最后一列中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03aa726d-0232-41ef-8d9c-794dc5b8aece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4054, 0.4054, 0.4054, 0.4054, 0.4054, 0.4054, 0.4054, 0.4054,\n",
       "       0.4054, 0.4054])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([0.4054]*10)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7edc8784-47b8-4d7c-9b97-6fc49667f067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned  x2_binned&x4  y_pred\n",
       "0  1.2  4.7   1   0  1        0.0        1.0           1.0  0.4054\n",
       "1  2.9  5.5   1   0  0        1.0        1.0           1.0  0.4054\n",
       "2  2.6  3.9   0   1  1        1.0        0.0           2.0  0.4054\n",
       "3  3.3  6.2   1   0  0        1.0        1.0           1.0  0.4054\n",
       "4  2.0  3.5   1   0  1        0.0        0.0           0.0  0.4054\n",
       "5  2.5  4.5   1   1  1        1.0        1.0           3.0  0.4054\n",
       "6  1.4  5.1   1   0  0        0.0        1.0           1.0  0.4054\n",
       "7  2.1  2.7   0   1  0        0.0        0.0           2.0  0.4054\n",
       "8  1.7  4.1   1   0  1        0.0        0.0           0.0  0.4054\n",
       "9  3.0  3.8   1   1  1        1.0        0.0           2.0  0.4054"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y_pred'] = y_pred\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a8d0c-131c-4700-96be-57d9ecc4ddda",
   "metadata": {},
   "source": [
    "接下来我们即可依据y_pred来计算每条样本的梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064490bf-a6a7-4259-bbe7-7f59d7f860d0",
   "metadata": {},
   "source": [
    "- 样本梯度与hes值计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc981fa9-9fac-4acc-8d35-d7e97e5589e1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们借助刚才定义的binary_cross_entropy_grad函数进行样本梯度计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74580d3b-5d4a-4ecd-89ce-98b7a1b0b2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -2.466699\n",
       "1    1.681802\n",
       "2   -2.466699\n",
       "3    1.681802\n",
       "4   -2.466699\n",
       "5   -2.466699\n",
       "6    1.681802\n",
       "7    1.681802\n",
       "8   -2.466699\n",
       "9   -2.466699\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cross_entropy_grad(data['y'], data['y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc01950-bcf5-4b96-a033-d3602eaea841",
   "metadata": {},
   "source": [
    "并将其追加到data数据集中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3501bad-dc10-4756-8970-352a785bce52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned  x2_binned&x4  y_pred      grad\n",
       "0  1.2  4.7   1   0  1        0.0        1.0           1.0  0.4054 -2.466699\n",
       "1  2.9  5.5   1   0  0        1.0        1.0           1.0  0.4054  1.681802\n",
       "2  2.6  3.9   0   1  1        1.0        0.0           2.0  0.4054 -2.466699\n",
       "3  3.3  6.2   1   0  0        1.0        1.0           1.0  0.4054  1.681802\n",
       "4  2.0  3.5   1   0  1        0.0        0.0           0.0  0.4054 -2.466699\n",
       "5  2.5  4.5   1   1  1        1.0        1.0           3.0  0.4054 -2.466699\n",
       "6  1.4  5.1   1   0  0        0.0        1.0           1.0  0.4054  1.681802\n",
       "7  2.1  2.7   0   1  0        0.0        0.0           2.0  0.4054  1.681802\n",
       "8  1.7  4.1   1   0  1        0.0        0.0           0.0  0.4054 -2.466699\n",
       "9  3.0  3.8   1   1  1        1.0        0.0           2.0  0.4054 -2.466699"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['grad'] = binary_cross_entropy_grad(data['y'], data['y_pred'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00921232-a304-4fe8-bea0-00d0cfddfe3a",
   "metadata": {},
   "source": [
    "然后再计算样本的hes值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5164651f-43ec-446c-98ec-0755fa1b8f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6.084606\n",
       "1    2.828461\n",
       "2    6.084606\n",
       "3    2.828461\n",
       "4    6.084606\n",
       "5    6.084606\n",
       "6    2.828461\n",
       "7    2.828461\n",
       "8    6.084606\n",
       "9    6.084606\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cross_entropy_hess(data['y'], data['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac131cf-4d33-480e-ac0b-a373d07c479c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>grad</th>\n",
       "      <th>hess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "      <td>2.828461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "      <td>2.828461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "      <td>2.828461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "      <td>2.828461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned  x2_binned&x4  y_pred      grad  \\\n",
       "0  1.2  4.7   1   0  1        0.0        1.0           1.0  0.4054 -2.466699   \n",
       "1  2.9  5.5   1   0  0        1.0        1.0           1.0  0.4054  1.681802   \n",
       "2  2.6  3.9   0   1  1        1.0        0.0           2.0  0.4054 -2.466699   \n",
       "3  3.3  6.2   1   0  0        1.0        1.0           1.0  0.4054  1.681802   \n",
       "4  2.0  3.5   1   0  1        0.0        0.0           0.0  0.4054 -2.466699   \n",
       "5  2.5  4.5   1   1  1        1.0        1.0           3.0  0.4054 -2.466699   \n",
       "6  1.4  5.1   1   0  0        0.0        1.0           1.0  0.4054  1.681802   \n",
       "7  2.1  2.7   0   1  0        0.0        0.0           2.0  0.4054  1.681802   \n",
       "8  1.7  4.1   1   0  1        0.0        0.0           0.0  0.4054 -2.466699   \n",
       "9  3.0  3.8   1   1  1        1.0        0.0           2.0  0.4054 -2.466699   \n",
       "\n",
       "       hess  \n",
       "0  6.084606  \n",
       "1  2.828461  \n",
       "2  6.084606  \n",
       "3  2.828461  \n",
       "4  6.084606  \n",
       "5  6.084606  \n",
       "6  2.828461  \n",
       "7  2.828461  \n",
       "8  6.084606  \n",
       "9  6.084606  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hess'] = binary_cross_entropy_hess(data['y'], data['y_pred'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d5d5b-789b-41c4-9f0d-8f85bb0d1e72",
   "metadata": {},
   "source": [
    "- GOSS抽样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf4b04-5eed-45f4-90f8-412031601c02",
   "metadata": {},
   "source": [
    "&emsp;&emsp;据此我们即可进一步执行GOSS抽样。这里我们假设top_rate=0.2，other_rate=0.5，由于我们样本量较少，因此这里设置的比例偏大。此时GOSS抽样过程如下，首先计算样本梯度绝对值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689a4306-3d33-4690-b253-3396fc31ce77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.466699\n",
       "1    1.681802\n",
       "2    2.466699\n",
       "3    1.681802\n",
       "4    2.466699\n",
       "5    2.466699\n",
       "6    1.681802\n",
       "7    1.681802\n",
       "8    2.466699\n",
       "9    2.466699\n",
       "Name: grad, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_gradients = np.abs(data['grad'])\n",
    "abs_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f65d8-ddcc-4003-93c4-2d511cccc38f",
   "metadata": {},
   "source": [
    "然后进行从大到小的索引排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78903d1c-b040-4f51-9c14-7ad6835000cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "2    4\n",
       "3    5\n",
       "4    8\n",
       "5    9\n",
       "6    1\n",
       "7    3\n",
       "8    6\n",
       "9    7\n",
       "Name: grad, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_index = np.argsort(-abs_gradients)\n",
    "sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae3a80-77b5-48b4-b8c7-a2304b0948c2",
   "metadata": {},
   "source": [
    "此时top_rate=0.2，other_rate=0.5，即从10条数据中挑选出梯度最大的2条数据，然后从剩下的8条数据中抽取50%，即抽取4条数据，共同构成本次GOSS抽样得到的训练数据集。这里我们先借助布尔索引先挑选出梯度最大的2条数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90741aa4-c42e-4722-a3b3-fb109ead81e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn_index = sorted_index[:2]\n",
    "topn_index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30247715-c304-4c6e-af0b-3633a88b38d6",
   "metadata": {},
   "source": [
    "两条数据抽取结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba3208f6-692f-4e99-b550-3ccd1f565c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>grad</th>\n",
       "      <th>hess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned  x2_binned&x4  y_pred      grad  \\\n",
       "0  1.2  4.7   1   0  1        0.0        1.0           1.0  0.4054 -2.466699   \n",
       "2  2.6  3.9   0   1  1        1.0        0.0           2.0  0.4054 -2.466699   \n",
       "\n",
       "       hess  \n",
       "0  6.084606  \n",
       "2  6.084606  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn_data = data.iloc[topn_index.values, :]\n",
    "topn_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a067451c-11bf-43e1-bebb-f01b922bbd9f",
   "metadata": {},
   "source": [
    "然后再从剩下的数据集中随机抽取4条数据，首先是找到剩余数据集索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3984e775-fb96-4448-ae58-9218a59c994d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    4\n",
       "3    5\n",
       "4    8\n",
       "5    9\n",
       "6    1\n",
       "7    3\n",
       "8    6\n",
       "9    7\n",
       "Name: grad, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_index[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aea141-6e7f-4acd-8deb-1fe10d8db752",
   "metadata": {},
   "source": [
    "然后进行抽样，这里采用无放回抽样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73ebd839-8df7-4680-9b1b-35bae41a0df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 8, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raten_index = np.random.choice(sorted_index[2:].values, size=4, replace=False)\n",
    "raten_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb0acf86-b30e-4508-8261-ab46acc9affd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>x1_binned</th>\n",
       "      <th>x2_binned</th>\n",
       "      <th>x2_binned&amp;x4</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>grad</th>\n",
       "      <th>hess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>-2.466699</td>\n",
       "      <td>6.084606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "      <td>2.828461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>1.681802</td>\n",
       "      <td>2.828461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2  x3  x4  y  x1_binned  x2_binned  x2_binned&x4  y_pred      grad  \\\n",
       "5  2.5  4.5   1   1  1        1.0        1.0           3.0  0.4054 -2.466699   \n",
       "8  1.7  4.1   1   0  1        0.0        0.0           0.0  0.4054 -2.466699   \n",
       "1  2.9  5.5   1   0  0        1.0        1.0           1.0  0.4054  1.681802   \n",
       "3  3.3  6.2   1   0  0        1.0        1.0           1.0  0.4054  1.681802   \n",
       "\n",
       "       hess  \n",
       "5  6.084606  \n",
       "8  6.084606  \n",
       "1  2.828461  \n",
       "3  2.828461  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raten_data = data.iloc[raten_index, :]\n",
    "raten_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d058bc1b-0da3-408e-805b-75ffc7a49626",
   "metadata": {},
   "source": [
    "至此，我们就完成了一次GOSS抽样全过程，接下来我们就将带入我们抽样得到的topn_data和raten_data带入进行模型训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5fef92-da66-4e31-8e8d-a3d5692ba502",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d95d27-1748-45d3-b424-73d036aa8325",
   "metadata": {},
   "source": [
    "- 课程节选自《机器学习实战训练营》正式课程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62906113-bb4c-4057-bfb8-d502202163bf",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/1.jpg\" alt=\"1\" style=\"zoom:20%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2b47e-ebe8-4b66-90bd-f791a278119e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;公开课内容节选自《机器学习实战训练营》正式课程，正式课程相比公开课，额外增加更具深度和LGBM数学原理推导、LGBM原生API使用和优化技巧，以及基于LGBM原生API的企业级实战案例，公开课与付费正课内容对比如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae6d11-6cc7-4a60-84ea-c6376e92220b",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/05b61eb9b6792c10ce8c6c221f7d140.png\" alt=\"05b61eb9b6792c10ce8c6c221f7d140\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c4560-5a91-40b1-bffd-66cc4272fbf8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果同学希望更进一步进行深度、系统的学习LightGBM及其他机器学习算法，欢迎大家报名《机器学习实战训练营（第六期）》付费正课，课程为130+小时完整体系大课，完整涵盖经典机器学习、集成学习、特征工程、模型融合、特征混合增强和企业级之战案例，总共6大模块，零基础直达机器学习算法岗中高级岗位要求，六年教学经验沉淀，千名学员口碑见证，超值体系大课等你来学！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d7488-c766-4e71-bb4a-eba15b6ae6a1",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20230215185442588.png\" alt=\"image-20230215185442588\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63fcbf-55b1-4c7c-953c-546b289db292",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20230215185629296.png\" alt=\"image-20230215185629296\" style=\"zoom:42.5%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3659263-360c-4a8a-a102-0d73c8449057",
   "metadata": {},
   "source": [
    "&emsp;&emsp;除了《机器学习实战训练营》课程外，我们还开设了《数据分析就业班》和《深度学习实战课》，在此查看详细课程介绍和课程大纲：https://appZe9inzwc2314.h5.xiaoeknow.com："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c405a0b-33f8-44a0-b25b-ef10ea1fb966",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20230214180459436.png\" alt=\"image-20230214180459436\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe2a1b-ebe5-4033-b3a6-8da2f1c29123",
   "metadata": {},
   "source": [
    "- **<font color='red'>第六期训练营课程尾单八折特惠进行时！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a565d-d7a3-41fa-b091-79b0d2d4b7ff",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/2.jpg\" alt=\"2\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d67f77-7949-4c2b-885e-84b38998d6cf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font size=3><center>扫码添加客服“小可爱”，或者手动添加客服微信：littlecat_1205       \n",
    "    >>>  <font color='red'>**回复“优惠”**</font>抢<font color='red'>**直播间限定折上折**        \n",
    "    **>>>  限量赠送授课老师亲自答疑服务！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f2d80-8abe-4753-ae8a-fd166235ca00",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/926380675d5976b65f5784be6db5f35.png\" alt=\"926380675d5976b65f5784be6db5f35\" style=\"zoom:50%;\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
